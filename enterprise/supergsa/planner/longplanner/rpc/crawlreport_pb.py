# This file automatically generated by protocol-compiler from enterprise/supergsa/planner/longplanner/rpc/crawlreport.proto
# DO NOT EDIT!

from google3.net.proto import ProtocolBuffer
import array
import thread
from google3.net.proto import _net_proto___parse__python

__pychecker__ = """maxreturns=0 maxbranches=0 no-callinit
                   unusednames=printElemNumber,debug_strs no-special"""

class CrawlReportRequest_UrlInfoParams(ProtocolBuffer.ProtocolMessage):
  def __init__(self, contents=None):
    self.url_ = ""
    self.has_url_ = 0
    if contents is not None: self.MergeFromString(contents)

  def url(self): return self.url_

  def set_url(self, x):
    self.has_url_ = 1
    self.url_ = x

  def clear_url(self):
    self.has_url_ = 0
    self.url_ = ""

  def has_url(self): return self.has_url_


  def MergeFrom(self, x):
    assert x is not self
    if (x.has_url()): self.set_url(x.url())

  def _CMergeFromString(self, s):
    _net_proto___parse__python.MergeFromString(self, 'CrawlReportRequest', s)

  def _CEncode(self):
    return _net_proto___parse__python.Encode(self, 'CrawlReportRequest')

  def _CToASCII(self, output_format):
    return _net_proto___parse__python.ToASCII(self, 'CrawlReportRequest', output_format)


  def ParseASCII(self, s):
    _net_proto___parse__python.ParseASCII(self, 'CrawlReportRequest', s)


  def ParseASCIIIgnoreUnknown(self, s):
    _net_proto___parse__python.ParseASCIIIgnoreUnknown(self, 'CrawlReportRequest', s)


  def Equals(self, x):
    if x is self: return 1
    if self.has_url_ != x.has_url_: return 0
    if self.has_url_ and self.url_ != x.url_: return 0
    return 1

  def __eq__(self, other):
    return (other is not None) and (other.__class__ == self.__class__) and self.Equals(other)

  def __ne__(self, other):
    return not (self == other)

  def IsInitialized(self, debug_strs=None):
    initialized = 1
    if (not self.has_url_):
      initialized = 0
      if debug_strs is not None:
        debug_strs.append('Required field: url not set.')
    return initialized

  def ByteSize(self):
    n = 0
    n += self.lengthString(len(self.url_))
    return n + 1

  def Clear(self):
    self.clear_url()

  def OutputUnchecked(self, out):
    out.putVarInt32(26)
    out.putPrefixedString(self.url_)

  def TryMerge(self, d):
    while 1:
      tt = d.getVarInt32()
      if tt == 20: break
      if tt == 26:
        self.set_url(d.getPrefixedString())
        continue
      # tag 0 is special: it's used to indicate an error.
      # so if we see it we raise an exception.
      if (tt == 0): raise ProtocolBuffer.ProtocolBufferDecodeError
      d.skipData(tt)


  def __str__(self, prefix="", printElemNumber=0):
    res=""
    if self.has_url_: res+=prefix+("Url: %s\n" % self.DebugFormatString(self.url_))
    return res

class CrawlReportRequest_CrawlQueueParams(ProtocolBuffer.ProtocolMessage):
  def __init__(self, contents=None):
    self.numurls_ = 0
    self.nexthours_ = 0
    self.host_ = ""
    self.has_numurls_ = 0
    self.has_nexthours_ = 0
    self.has_host_ = 0
    if contents is not None: self.MergeFromString(contents)

  def numurls(self): return self.numurls_

  def set_numurls(self, x):
    self.has_numurls_ = 1
    self.numurls_ = x

  def clear_numurls(self):
    self.has_numurls_ = 0
    self.numurls_ = 0

  def has_numurls(self): return self.has_numurls_

  def nexthours(self): return self.nexthours_

  def set_nexthours(self, x):
    self.has_nexthours_ = 1
    self.nexthours_ = x

  def clear_nexthours(self):
    self.has_nexthours_ = 0
    self.nexthours_ = 0

  def has_nexthours(self): return self.has_nexthours_

  def host(self): return self.host_

  def set_host(self, x):
    self.has_host_ = 1
    self.host_ = x

  def clear_host(self):
    self.has_host_ = 0
    self.host_ = ""

  def has_host(self): return self.has_host_


  def MergeFrom(self, x):
    assert x is not self
    if (x.has_numurls()): self.set_numurls(x.numurls())
    if (x.has_nexthours()): self.set_nexthours(x.nexthours())
    if (x.has_host()): self.set_host(x.host())

  def _CMergeFromString(self, s):
    _net_proto___parse__python.MergeFromString(self, 'CrawlReportRequest', s)

  def _CEncode(self):
    return _net_proto___parse__python.Encode(self, 'CrawlReportRequest')

  def _CToASCII(self, output_format):
    return _net_proto___parse__python.ToASCII(self, 'CrawlReportRequest', output_format)


  def ParseASCII(self, s):
    _net_proto___parse__python.ParseASCII(self, 'CrawlReportRequest', s)


  def ParseASCIIIgnoreUnknown(self, s):
    _net_proto___parse__python.ParseASCIIIgnoreUnknown(self, 'CrawlReportRequest', s)


  def Equals(self, x):
    if x is self: return 1
    if self.has_numurls_ != x.has_numurls_: return 0
    if self.has_numurls_ and self.numurls_ != x.numurls_: return 0
    if self.has_nexthours_ != x.has_nexthours_: return 0
    if self.has_nexthours_ and self.nexthours_ != x.nexthours_: return 0
    if self.has_host_ != x.has_host_: return 0
    if self.has_host_ and self.host_ != x.host_: return 0
    return 1

  def __eq__(self, other):
    return (other is not None) and (other.__class__ == self.__class__) and self.Equals(other)

  def __ne__(self, other):
    return not (self == other)

  def IsInitialized(self, debug_strs=None):
    initialized = 1
    if (not self.has_numurls_):
      initialized = 0
      if debug_strs is not None:
        debug_strs.append('Required field: numurls not set.')
    if (not self.has_nexthours_):
      initialized = 0
      if debug_strs is not None:
        debug_strs.append('Required field: nexthours not set.')
    return initialized

  def ByteSize(self):
    n = 0
    n += self.lengthVarInt64(self.numurls_)
    n += self.lengthVarInt64(self.nexthours_)
    if (self.has_host_): n += 1 + self.lengthString(len(self.host_))
    return n + 2

  def Clear(self):
    self.clear_numurls()
    self.clear_nexthours()
    self.clear_host()

  def OutputUnchecked(self, out):
    out.putVarInt32(40)
    out.putVarInt32(self.numurls_)
    out.putVarInt32(48)
    out.putVarInt32(self.nexthours_)
    if (self.has_host_):
      out.putVarInt32(58)
      out.putPrefixedString(self.host_)

  def TryMerge(self, d):
    while 1:
      tt = d.getVarInt32()
      if tt == 36: break
      if tt == 40:
        self.set_numurls(d.getVarInt32())
        continue
      if tt == 48:
        self.set_nexthours(d.getVarInt32())
        continue
      if tt == 58:
        self.set_host(d.getPrefixedString())
        continue
      # tag 0 is special: it's used to indicate an error.
      # so if we see it we raise an exception.
      if (tt == 0): raise ProtocolBuffer.ProtocolBufferDecodeError
      d.skipData(tt)


  def __str__(self, prefix="", printElemNumber=0):
    res=""
    if self.has_numurls_: res+=prefix+("NumURLs: %s\n" % self.DebugFormatInt32(self.numurls_))
    if self.has_nexthours_: res+=prefix+("NextHours: %s\n" % self.DebugFormatInt32(self.nexthours_))
    if self.has_host_: res+=prefix+("Host: %s\n" % self.DebugFormatString(self.host_))
    return res

class CrawlReportRequest(ProtocolBuffer.ProtocolMessage):

  URL_INFO_COMMAND =    0 
  CRAWL_QUEUE_COMMAND =    1 

  _CrawlReportCommand_NAMES = {
    0: "URL_INFO_COMMAND",
    1: "CRAWL_QUEUE_COMMAND",
  }

  def CrawlReportCommand_Name(cls, x): return cls._CrawlReportCommand_NAMES.get(x, "")
  CrawlReportCommand_Name = classmethod(CrawlReportCommand_Name)

  def __init__(self, contents=None):
    self.commandtype_ = 0
    self.urlinfoparams_ = None
    self.crawlqueueparams_ = None
    self.has_commandtype_ = 0
    self.has_urlinfoparams_ = 0
    self.has_crawlqueueparams_ = 0
    self.lazy_init_lock_ = thread.allocate_lock()
    if contents is not None: self.MergeFromString(contents)

  def commandtype(self): return self.commandtype_

  def set_commandtype(self, x):
    self.has_commandtype_ = 1
    self.commandtype_ = x

  def clear_commandtype(self):
    self.has_commandtype_ = 0
    self.commandtype_ = 0

  def has_commandtype(self): return self.has_commandtype_

  def urlinfoparams(self):
    if self.urlinfoparams_ is None:
      self.lazy_init_lock_.acquire()
      try:
        if self.urlinfoparams_ is None: self.urlinfoparams_ = CrawlReportRequest_UrlInfoParams()
      finally:
        self.lazy_init_lock_.release()
    return self.urlinfoparams_

  def mutable_urlinfoparams(self): self.has_urlinfoparams_ = 1; return self.urlinfoparams()

  def clear_urlinfoparams(self):
    #Warning: this method does not acquire the lock.
    self.has_urlinfoparams_ = 0;
    if self.urlinfoparams_ is not None: self.urlinfoparams_.Clear()

  def has_urlinfoparams(self): return self.has_urlinfoparams_

  def crawlqueueparams(self):
    if self.crawlqueueparams_ is None:
      self.lazy_init_lock_.acquire()
      try:
        if self.crawlqueueparams_ is None: self.crawlqueueparams_ = CrawlReportRequest_CrawlQueueParams()
      finally:
        self.lazy_init_lock_.release()
    return self.crawlqueueparams_

  def mutable_crawlqueueparams(self): self.has_crawlqueueparams_ = 1; return self.crawlqueueparams()

  def clear_crawlqueueparams(self):
    #Warning: this method does not acquire the lock.
    self.has_crawlqueueparams_ = 0;
    if self.crawlqueueparams_ is not None: self.crawlqueueparams_.Clear()

  def has_crawlqueueparams(self): return self.has_crawlqueueparams_


  def MergeFrom(self, x):
    assert x is not self
    if (x.has_commandtype()): self.set_commandtype(x.commandtype())
    if (x.has_urlinfoparams()): self.mutable_urlinfoparams().MergeFrom(x.urlinfoparams())
    if (x.has_crawlqueueparams()): self.mutable_crawlqueueparams().MergeFrom(x.crawlqueueparams())

  def _CMergeFromString(self, s):
    _net_proto___parse__python.MergeFromString(self, 'CrawlReportRequest', s)

  def _CEncode(self):
    return _net_proto___parse__python.Encode(self, 'CrawlReportRequest')

  def _CToASCII(self, output_format):
    return _net_proto___parse__python.ToASCII(self, 'CrawlReportRequest', output_format)


  def ParseASCII(self, s):
    _net_proto___parse__python.ParseASCII(self, 'CrawlReportRequest', s)


  def ParseASCIIIgnoreUnknown(self, s):
    _net_proto___parse__python.ParseASCIIIgnoreUnknown(self, 'CrawlReportRequest', s)


  def Equals(self, x):
    if x is self: return 1
    if self.has_commandtype_ != x.has_commandtype_: return 0
    if self.has_commandtype_ and self.commandtype_ != x.commandtype_: return 0
    if self.has_urlinfoparams_ != x.has_urlinfoparams_: return 0
    if self.has_urlinfoparams_ and self.urlinfoparams_ != x.urlinfoparams_: return 0
    if self.has_crawlqueueparams_ != x.has_crawlqueueparams_: return 0
    if self.has_crawlqueueparams_ and self.crawlqueueparams_ != x.crawlqueueparams_: return 0
    return 1

  def __eq__(self, other):
    return (other is not None) and (other.__class__ == self.__class__) and self.Equals(other)

  def __ne__(self, other):
    return not (self == other)

  def IsInitialized(self, debug_strs=None):
    initialized = 1
    if (not self.has_commandtype_):
      initialized = 0
      if debug_strs is not None:
        debug_strs.append('Required field: commandtype not set.')
    if (self.has_urlinfoparams_ and not self.urlinfoparams_.IsInitialized(debug_strs)): initialized = 0
    if (self.has_crawlqueueparams_ and not self.crawlqueueparams_.IsInitialized(debug_strs)): initialized = 0
    return initialized

  def ByteSize(self):
    n = 0
    n += self.lengthVarInt64(self.commandtype_)
    if (self.has_urlinfoparams_): n += 2 + self.urlinfoparams_.ByteSize()
    if (self.has_crawlqueueparams_): n += 2 + self.crawlqueueparams_.ByteSize()
    return n + 1

  def Clear(self):
    self.clear_commandtype()
    self.clear_urlinfoparams()
    self.clear_crawlqueueparams()

  def OutputUnchecked(self, out):
    out.putVarInt32(8)
    out.putVarInt32(self.commandtype_)
    if (self.has_urlinfoparams_):
      out.putVarInt32(19)
      self.urlinfoparams_.OutputUnchecked(out)
      out.putVarInt32(20)
    if (self.has_crawlqueueparams_):
      out.putVarInt32(35)
      self.crawlqueueparams_.OutputUnchecked(out)
      out.putVarInt32(36)

  def TryMerge(self, d):
    while d.avail() > 0:
      tt = d.getVarInt32()
      if tt == 8:
        self.set_commandtype(d.getVarInt32())
        continue
      if tt == 19:
        self.mutable_urlinfoparams().TryMerge(d)
        continue
      if tt == 35:
        self.mutable_crawlqueueparams().TryMerge(d)
        continue
      # tag 0 is special: it's used to indicate an error.
      # so if we see it we raise an exception.
      if (tt == 0): raise ProtocolBuffer.ProtocolBufferDecodeError
      d.skipData(tt)


  def __str__(self, prefix="", printElemNumber=0):
    res=""
    if self.has_commandtype_: res+=prefix+("CommandType: %s\n" % self.DebugFormatInt32(self.commandtype_))
    if self.has_urlinfoparams_:
      res+=prefix+"UrlInfoParams {\n"
      res+=self.urlinfoparams_.__str__(prefix + "  ", printElemNumber)
      res+=prefix+"}\n"
    if self.has_crawlqueueparams_:
      res+=prefix+"CrawlQueueParams {\n"
      res+=self.crawlqueueparams_.__str__(prefix + "  ", printElemNumber)
      res+=prefix+"}\n"
    return res

  kCommandType = 1
  kUrlInfoParamsGroup = 2
  kUrlInfoParamsUrl = 3
  kCrawlQueueParamsGroup = 4
  kCrawlQueueParamsNumURLs = 5
  kCrawlQueueParamsNextHours = 6
  kCrawlQueueParamsHost = 7

  _TEXT = (
   "ErrorCode",  #   0
   "CommandType",  #   1
   "UrlInfoParams",  #   2
   "Url",  #   3
   "CrawlQueueParams",  #   4
   "NumURLs",  #   5
   "NextHours",  #   6
   "Host",  #   7
  )

  _TYPES = (
   ProtocolBuffer.Encoder.NUMERIC,  #   0
   ProtocolBuffer.Encoder.NUMERIC,  #   1

   ProtocolBuffer.Encoder.STARTGROUP,  #   2

   ProtocolBuffer.Encoder.STRING,  #   3

   ProtocolBuffer.Encoder.STARTGROUP,  #   4

   ProtocolBuffer.Encoder.NUMERIC,  #   5

   ProtocolBuffer.Encoder.NUMERIC,  #   6

   ProtocolBuffer.Encoder.STRING,  #   7

  )

  # stylesheet for XML output
  _STYLE = \
   """"""
  _STYLE_CONTENT_TYPE = \
   """"""
  _SERIALIZED_DESCRIPTOR = array.array('B', [
    0x5a,
    0x3d,
    0x65,
    0x6e,
    0x74,
    0x65,
    0x72,
    0x70,
    0x72,
    0x69,
    0x73,
    0x65,
    0x2f,
    0x73,
    0x75,
    0x70,
    0x65,
    0x72,
    0x67,
    0x73,
    0x61,
    0x2f,
    0x70,
    0x6c,
    0x61,
    0x6e,
    0x6e,
    0x65,
    0x72,
    0x2f,
    0x6c,
    0x6f,
    0x6e,
    0x67,
    0x70,
    0x6c,
    0x61,
    0x6e,
    0x6e,
    0x65,
    0x72,
    0x2f,
    0x72,
    0x70,
    0x63,
    0x2f,
    0x63,
    0x72,
    0x61,
    0x77,
    0x6c,
    0x72,
    0x65,
    0x70,
    0x6f,
    0x72,
    0x74,
    0x2e,
    0x70,
    0x72,
    0x6f,
    0x74,
    0x6f,
    0x0a,
    0x12,
    0x43,
    0x72,
    0x61,
    0x77,
    0x6c,
    0x52,
    0x65,
    0x70,
    0x6f,
    0x72,
    0x74,
    0x52,
    0x65,
    0x71,
    0x75,
    0x65,
    0x73,
    0x74,
    0x13,
    0x1a,
    0x0b,
    0x43,
    0x6f,
    0x6d,
    0x6d,
    0x61,
    0x6e,
    0x64,
    0x54,
    0x79,
    0x70,
    0x65,
    0x20,
    0x01,
    0x28,
    0x00,
    0x30,
    0x05,
    0x38,
    0x02,
    0x14,
    0x13,
    0x1a,
    0x0d,
    0x55,
    0x72,
    0x6c,
    0x49,
    0x6e,
    0x66,
    0x6f,
    0x50,
    0x61,
    0x72,
    0x61,
    0x6d,
    0x73,
    0x20,
    0x02,
    0x28,
    0x03,
    0x30,
    0x0a,
    0x38,
    0x01,
    0x14,
    0x13,
    0x1a,
    0x11,
    0x55,
    0x72,
    0x6c,
    0x49,
    0x6e,
    0x66,
    0x6f,
    0x50,
    0x61,
    0x72,
    0x61,
    0x6d,
    0x73,
    0x2e,
    0x55,
    0x72,
    0x6c,
    0x20,
    0x03,
    0x28,
    0x02,
    0x30,
    0x09,
    0x38,
    0x02,
    0x60,
    0x01,
    0x14,
    0x13,
    0x1a,
    0x10,
    0x43,
    0x72,
    0x61,
    0x77,
    0x6c,
    0x51,
    0x75,
    0x65,
    0x75,
    0x65,
    0x50,
    0x61,
    0x72,
    0x61,
    0x6d,
    0x73,
    0x20,
    0x04,
    0x28,
    0x03,
    0x30,
    0x0a,
    0x38,
    0x01,
    0x14,
    0x13,
    0x1a,
    0x18,
    0x43,
    0x72,
    0x61,
    0x77,
    0x6c,
    0x51,
    0x75,
    0x65,
    0x75,
    0x65,
    0x50,
    0x61,
    0x72,
    0x61,
    0x6d,
    0x73,
    0x2e,
    0x4e,
    0x75,
    0x6d,
    0x55,
    0x52,
    0x4c,
    0x73,
    0x20,
    0x05,
    0x28,
    0x00,
    0x30,
    0x05,
    0x38,
    0x02,
    0x60,
    0x03,
    0x14,
    0x13,
    0x1a,
    0x1a,
    0x43,
    0x72,
    0x61,
    0x77,
    0x6c,
    0x51,
    0x75,
    0x65,
    0x75,
    0x65,
    0x50,
    0x61,
    0x72,
    0x61,
    0x6d,
    0x73,
    0x2e,
    0x4e,
    0x65,
    0x78,
    0x74,
    0x48,
    0x6f,
    0x75,
    0x72,
    0x73,
    0x20,
    0x06,
    0x28,
    0x00,
    0x30,
    0x05,
    0x38,
    0x02,
    0x60,
    0x03,
    0x14,
    0x13,
    0x1a,
    0x15,
    0x43,
    0x72,
    0x61,
    0x77,
    0x6c,
    0x51,
    0x75,
    0x65,
    0x75,
    0x65,
    0x50,
    0x61,
    0x72,
    0x61,
    0x6d,
    0x73,
    0x2e,
    0x48,
    0x6f,
    0x73,
    0x74,
    0x20,
    0x07,
    0x28,
    0x02,
    0x30,
    0x09,
    0x38,
    0x01,
    0x60,
    0x03,
    0x14,
    0x73,
    0x7a,
    0x12,
    0x43,
    0x72,
    0x61,
    0x77,
    0x6c,
    0x52,
    0x65,
    0x70,
    0x6f,
    0x72,
    0x74,
    0x43,
    0x6f,
    0x6d,
    0x6d,
    0x61,
    0x6e,
    0x64,
    0x8b,
    0x01,
    0x92,
    0x01,
    0x10,
    0x55,
    0x52,
    0x4c,
    0x5f,
    0x49,
    0x4e,
    0x46,
    0x4f,
    0x5f,
    0x43,
    0x4f,
    0x4d,
    0x4d,
    0x41,
    0x4e,
    0x44,
    0x98,
    0x01,
    0x00,
    0x8c,
    0x01,
    0x8b,
    0x01,
    0x92,
    0x01,
    0x13,
    0x43,
    0x52,
    0x41,
    0x57,
    0x4c,
    0x5f,
    0x51,
    0x55,
    0x45,
    0x55,
    0x45,
    0x5f,
    0x43,
    0x4f,
    0x4d,
    0x4d,
    0x41,
    0x4e,
    0x44,
    0x98,
    0x01,
    0x01,
    0x8c,
    0x01,
    0x74,
    ])
  _net_proto___parse__python.RegisterType(_SERIALIZED_DESCRIPTOR.tostring())
class UrlInfo(ProtocolBuffer.ProtocolMessage):
  def __init__(self, contents=None):
    self.path_ = ""
    self.pagerank_ = 0
    self.lastcrawledtime_ = 0
    self.changeinterval_ = 0
    self.nextcrawltime_ = 0
    self.isprobablyindexed_ = 0
    self.priority_ = 0.0
    self.has_path_ = 0
    self.has_pagerank_ = 0
    self.has_lastcrawledtime_ = 0
    self.has_changeinterval_ = 0
    self.has_nextcrawltime_ = 0
    self.has_isprobablyindexed_ = 0
    self.has_priority_ = 0
    if contents is not None: self.MergeFromString(contents)

  def path(self): return self.path_

  def set_path(self, x):
    self.has_path_ = 1
    self.path_ = x

  def clear_path(self):
    self.has_path_ = 0
    self.path_ = ""

  def has_path(self): return self.has_path_

  def pagerank(self): return self.pagerank_

  def set_pagerank(self, x):
    self.has_pagerank_ = 1
    self.pagerank_ = x

  def clear_pagerank(self):
    self.has_pagerank_ = 0
    self.pagerank_ = 0

  def has_pagerank(self): return self.has_pagerank_

  def lastcrawledtime(self): return self.lastcrawledtime_

  def set_lastcrawledtime(self, x):
    self.has_lastcrawledtime_ = 1
    self.lastcrawledtime_ = x

  def clear_lastcrawledtime(self):
    self.has_lastcrawledtime_ = 0
    self.lastcrawledtime_ = 0

  def has_lastcrawledtime(self): return self.has_lastcrawledtime_

  def changeinterval(self): return self.changeinterval_

  def set_changeinterval(self, x):
    self.has_changeinterval_ = 1
    self.changeinterval_ = x

  def clear_changeinterval(self):
    self.has_changeinterval_ = 0
    self.changeinterval_ = 0

  def has_changeinterval(self): return self.has_changeinterval_

  def nextcrawltime(self): return self.nextcrawltime_

  def set_nextcrawltime(self, x):
    self.has_nextcrawltime_ = 1
    self.nextcrawltime_ = x

  def clear_nextcrawltime(self):
    self.has_nextcrawltime_ = 0
    self.nextcrawltime_ = 0

  def has_nextcrawltime(self): return self.has_nextcrawltime_

  def isprobablyindexed(self): return self.isprobablyindexed_

  def set_isprobablyindexed(self, x):
    self.has_isprobablyindexed_ = 1
    self.isprobablyindexed_ = x

  def clear_isprobablyindexed(self):
    self.has_isprobablyindexed_ = 0
    self.isprobablyindexed_ = 0

  def has_isprobablyindexed(self): return self.has_isprobablyindexed_

  def priority(self): return self.priority_

  def set_priority(self, x):
    self.has_priority_ = 1
    self.priority_ = x

  def clear_priority(self):
    self.has_priority_ = 0
    self.priority_ = 0.0

  def has_priority(self): return self.has_priority_


  def MergeFrom(self, x):
    assert x is not self
    if (x.has_path()): self.set_path(x.path())
    if (x.has_pagerank()): self.set_pagerank(x.pagerank())
    if (x.has_lastcrawledtime()): self.set_lastcrawledtime(x.lastcrawledtime())
    if (x.has_changeinterval()): self.set_changeinterval(x.changeinterval())
    if (x.has_nextcrawltime()): self.set_nextcrawltime(x.nextcrawltime())
    if (x.has_isprobablyindexed()): self.set_isprobablyindexed(x.isprobablyindexed())
    if (x.has_priority()): self.set_priority(x.priority())

  def _CMergeFromString(self, s):
    _net_proto___parse__python.MergeFromString(self, 'UrlInfo', s)

  def _CEncode(self):
    return _net_proto___parse__python.Encode(self, 'UrlInfo')

  def _CToASCII(self, output_format):
    return _net_proto___parse__python.ToASCII(self, 'UrlInfo', output_format)


  def ParseASCII(self, s):
    _net_proto___parse__python.ParseASCII(self, 'UrlInfo', s)


  def ParseASCIIIgnoreUnknown(self, s):
    _net_proto___parse__python.ParseASCIIIgnoreUnknown(self, 'UrlInfo', s)


  def Equals(self, x):
    if x is self: return 1
    if self.has_path_ != x.has_path_: return 0
    if self.has_path_ and self.path_ != x.path_: return 0
    if self.has_pagerank_ != x.has_pagerank_: return 0
    if self.has_pagerank_ and self.pagerank_ != x.pagerank_: return 0
    if self.has_lastcrawledtime_ != x.has_lastcrawledtime_: return 0
    if self.has_lastcrawledtime_ and self.lastcrawledtime_ != x.lastcrawledtime_: return 0
    if self.has_changeinterval_ != x.has_changeinterval_: return 0
    if self.has_changeinterval_ and self.changeinterval_ != x.changeinterval_: return 0
    if self.has_nextcrawltime_ != x.has_nextcrawltime_: return 0
    if self.has_nextcrawltime_ and self.nextcrawltime_ != x.nextcrawltime_: return 0
    if self.has_isprobablyindexed_ != x.has_isprobablyindexed_: return 0
    if self.has_isprobablyindexed_ and self.isprobablyindexed_ != x.isprobablyindexed_: return 0
    if self.has_priority_ != x.has_priority_: return 0
    if self.has_priority_ and self.priority_ != x.priority_: return 0
    return 1

  def __eq__(self, other):
    return (other is not None) and (other.__class__ == self.__class__) and self.Equals(other)

  def __ne__(self, other):
    return not (self == other)

  def IsInitialized(self, debug_strs=None):
    initialized = 1
    if (not self.has_path_):
      initialized = 0
      if debug_strs is not None:
        debug_strs.append('Required field: path not set.')
    return initialized

  def ByteSize(self):
    n = 0
    n += self.lengthString(len(self.path_))
    if (self.has_pagerank_): n += 1 + self.lengthVarInt64(self.pagerank_)
    if (self.has_lastcrawledtime_): n += 1 + self.lengthVarInt64(self.lastcrawledtime_)
    if (self.has_changeinterval_): n += 1 + self.lengthVarInt64(self.changeinterval_)
    if (self.has_nextcrawltime_): n += 1 + self.lengthVarInt64(self.nextcrawltime_)
    if (self.has_isprobablyindexed_): n += 2
    if (self.has_priority_): n += 9
    return n + 1

  def Clear(self):
    self.clear_path()
    self.clear_pagerank()
    self.clear_lastcrawledtime()
    self.clear_changeinterval()
    self.clear_nextcrawltime()
    self.clear_isprobablyindexed()
    self.clear_priority()

  def OutputUnchecked(self, out):
    out.putVarInt32(10)
    out.putPrefixedString(self.path_)
    if (self.has_pagerank_):
      out.putVarInt32(16)
      out.putVarInt32(self.pagerank_)
    if (self.has_lastcrawledtime_):
      out.putVarInt32(24)
      out.putVarInt32(self.lastcrawledtime_)
    if (self.has_changeinterval_):
      out.putVarInt32(32)
      out.putVarInt32(self.changeinterval_)
    if (self.has_nextcrawltime_):
      out.putVarInt32(40)
      out.putVarInt32(self.nextcrawltime_)
    if (self.has_isprobablyindexed_):
      out.putVarInt32(48)
      out.putBoolean(self.isprobablyindexed_)
    if (self.has_priority_):
      out.putVarInt32(57)
      out.putDouble(self.priority_)

  def TryMerge(self, d):
    while d.avail() > 0:
      tt = d.getVarInt32()
      if tt == 10:
        self.set_path(d.getPrefixedString())
        continue
      if tt == 16:
        self.set_pagerank(d.getVarInt32())
        continue
      if tt == 24:
        self.set_lastcrawledtime(d.getVarInt32())
        continue
      if tt == 32:
        self.set_changeinterval(d.getVarInt32())
        continue
      if tt == 40:
        self.set_nextcrawltime(d.getVarInt32())
        continue
      if tt == 48:
        self.set_isprobablyindexed(d.getBoolean())
        continue
      if tt == 57:
        self.set_priority(d.getDouble())
        continue
      # tag 0 is special: it's used to indicate an error.
      # so if we see it we raise an exception.
      if (tt == 0): raise ProtocolBuffer.ProtocolBufferDecodeError
      d.skipData(tt)


  def __str__(self, prefix="", printElemNumber=0):
    res=""
    if self.has_path_: res+=prefix+("Path: %s\n" % self.DebugFormatString(self.path_))
    if self.has_pagerank_: res+=prefix+("PageRank: %s\n" % self.DebugFormatInt32(self.pagerank_))
    if self.has_lastcrawledtime_: res+=prefix+("LastCrawledTime: %s\n" % self.DebugFormatInt32(self.lastcrawledtime_))
    if self.has_changeinterval_: res+=prefix+("ChangeInterval: %s\n" % self.DebugFormatInt32(self.changeinterval_))
    if self.has_nextcrawltime_: res+=prefix+("NextCrawlTime: %s\n" % self.DebugFormatInt32(self.nextcrawltime_))
    if self.has_isprobablyindexed_: res+=prefix+("IsProbablyIndexed: %s\n" % self.DebugFormatBool(self.isprobablyindexed_))
    if self.has_priority_: res+=prefix+("Priority: %s\n" % self.DebugFormat(self.priority_))
    return res

  kPath = 1
  kPageRank = 2
  kLastCrawledTime = 3
  kChangeInterval = 4
  kNextCrawlTime = 5
  kIsProbablyIndexed = 6
  kPriority = 7

  _TEXT = (
   "ErrorCode",  #   0
   "Path",  #   1
   "PageRank",  #   2
   "LastCrawledTime",  #   3
   "ChangeInterval",  #   4
   "NextCrawlTime",  #   5
   "IsProbablyIndexed",  #   6
   "Priority",  #   7
  )

  _TYPES = (
   ProtocolBuffer.Encoder.NUMERIC,  #   0
   ProtocolBuffer.Encoder.STRING,  #   1

   ProtocolBuffer.Encoder.NUMERIC,  #   2

   ProtocolBuffer.Encoder.NUMERIC,  #   3

   ProtocolBuffer.Encoder.NUMERIC,  #   4

   ProtocolBuffer.Encoder.NUMERIC,  #   5

   ProtocolBuffer.Encoder.NUMERIC,  #   6

   ProtocolBuffer.Encoder.DOUBLE,  #   7

  )

  # stylesheet for XML output
  _STYLE = \
   """"""
  _STYLE_CONTENT_TYPE = \
   """"""
  _SERIALIZED_DESCRIPTOR = array.array('B', [
    0x5a,
    0x3d,
    0x65,
    0x6e,
    0x74,
    0x65,
    0x72,
    0x70,
    0x72,
    0x69,
    0x73,
    0x65,
    0x2f,
    0x73,
    0x75,
    0x70,
    0x65,
    0x72,
    0x67,
    0x73,
    0x61,
    0x2f,
    0x70,
    0x6c,
    0x61,
    0x6e,
    0x6e,
    0x65,
    0x72,
    0x2f,
    0x6c,
    0x6f,
    0x6e,
    0x67,
    0x70,
    0x6c,
    0x61,
    0x6e,
    0x6e,
    0x65,
    0x72,
    0x2f,
    0x72,
    0x70,
    0x63,
    0x2f,
    0x63,
    0x72,
    0x61,
    0x77,
    0x6c,
    0x72,
    0x65,
    0x70,
    0x6f,
    0x72,
    0x74,
    0x2e,
    0x70,
    0x72,
    0x6f,
    0x74,
    0x6f,
    0x0a,
    0x07,
    0x55,
    0x72,
    0x6c,
    0x49,
    0x6e,
    0x66,
    0x6f,
    0x13,
    0x1a,
    0x04,
    0x50,
    0x61,
    0x74,
    0x68,
    0x20,
    0x01,
    0x28,
    0x02,
    0x30,
    0x09,
    0x38,
    0x02,
    0x14,
    0x13,
    0x1a,
    0x08,
    0x50,
    0x61,
    0x67,
    0x65,
    0x52,
    0x61,
    0x6e,
    0x6b,
    0x20,
    0x02,
    0x28,
    0x00,
    0x30,
    0x05,
    0x38,
    0x01,
    0x14,
    0x13,
    0x1a,
    0x0f,
    0x4c,
    0x61,
    0x73,
    0x74,
    0x43,
    0x72,
    0x61,
    0x77,
    0x6c,
    0x65,
    0x64,
    0x54,
    0x69,
    0x6d,
    0x65,
    0x20,
    0x03,
    0x28,
    0x00,
    0x30,
    0x05,
    0x38,
    0x01,
    0x14,
    0x13,
    0x1a,
    0x0e,
    0x43,
    0x68,
    0x61,
    0x6e,
    0x67,
    0x65,
    0x49,
    0x6e,
    0x74,
    0x65,
    0x72,
    0x76,
    0x61,
    0x6c,
    0x20,
    0x04,
    0x28,
    0x00,
    0x30,
    0x05,
    0x38,
    0x01,
    0x14,
    0x13,
    0x1a,
    0x0d,
    0x4e,
    0x65,
    0x78,
    0x74,
    0x43,
    0x72,
    0x61,
    0x77,
    0x6c,
    0x54,
    0x69,
    0x6d,
    0x65,
    0x20,
    0x05,
    0x28,
    0x00,
    0x30,
    0x05,
    0x38,
    0x01,
    0x14,
    0x13,
    0x1a,
    0x11,
    0x49,
    0x73,
    0x50,
    0x72,
    0x6f,
    0x62,
    0x61,
    0x62,
    0x6c,
    0x79,
    0x49,
    0x6e,
    0x64,
    0x65,
    0x78,
    0x65,
    0x64,
    0x20,
    0x06,
    0x28,
    0x00,
    0x30,
    0x08,
    0x38,
    0x01,
    0x14,
    0x13,
    0x1a,
    0x08,
    0x50,
    0x72,
    0x69,
    0x6f,
    0x72,
    0x69,
    0x74,
    0x79,
    0x20,
    0x07,
    0x28,
    0x01,
    0x30,
    0x01,
    0x38,
    0x01,
    0x14,
    ])
  _net_proto___parse__python.RegisterType(_SERIALIZED_DESCRIPTOR.tostring())
class CrawlQueueResponse_HostQueue(ProtocolBuffer.ProtocolMessage):
  def __init__(self, contents=None):
    self.host_ = ""
    self.urls_ = []
    self.has_host_ = 0
    if contents is not None: self.MergeFromString(contents)

  def host(self): return self.host_

  def set_host(self, x):
    self.has_host_ = 1
    self.host_ = x

  def clear_host(self):
    self.has_host_ = 0
    self.host_ = ""

  def has_host(self): return self.has_host_

  def urls_size(self): return len(self.urls_)
  def urls_list(self): return self.urls_

  def urls(self, i):
    return self.urls_[i]

  def mutable_urls(self, i):
    return self.urls_[i]

  def add_urls(self):
    x = UrlInfo()
    self.urls_.append(x)
    return x

  def clear_urls(self):
    self.urls_ = []

  def MergeFrom(self, x):
    assert x is not self
    if (x.has_host()): self.set_host(x.host())
    for i in xrange(x.urls_size()): self.add_urls().CopyFrom(x.urls(i))

  def _CMergeFromString(self, s):
    _net_proto___parse__python.MergeFromString(self, 'CrawlQueueResponse', s)

  def _CEncode(self):
    return _net_proto___parse__python.Encode(self, 'CrawlQueueResponse')

  def _CToASCII(self, output_format):
    return _net_proto___parse__python.ToASCII(self, 'CrawlQueueResponse', output_format)


  def ParseASCII(self, s):
    _net_proto___parse__python.ParseASCII(self, 'CrawlQueueResponse', s)


  def ParseASCIIIgnoreUnknown(self, s):
    _net_proto___parse__python.ParseASCIIIgnoreUnknown(self, 'CrawlQueueResponse', s)


  def Equals(self, x):
    if x is self: return 1
    if self.has_host_ != x.has_host_: return 0
    if self.has_host_ and self.host_ != x.host_: return 0
    if len(self.urls_) != len(x.urls_): return 0
    for e1, e2 in zip(self.urls_, x.urls_):
      if e1 != e2: return 0
    return 1

  def __eq__(self, other):
    return (other is not None) and (other.__class__ == self.__class__) and self.Equals(other)

  def __ne__(self, other):
    return not (self == other)

  def IsInitialized(self, debug_strs=None):
    initialized = 1
    if (not self.has_host_):
      initialized = 0
      if debug_strs is not None:
        debug_strs.append('Required field: host not set.')
    for i in xrange(len(self.urls_)):
      if (not self.urls_[i].IsInitialized(debug_strs)): initialized=0
    return initialized

  def ByteSize(self):
    n = 0
    n += self.lengthString(len(self.host_))
    n += 1 * len(self.urls_)
    for i in xrange(len(self.urls_)): n += self.lengthString(self.urls_[i].ByteSize())
    return n + 1

  def Clear(self):
    self.clear_host()
    self.clear_urls()

  def OutputUnchecked(self, out):
    out.putVarInt32(34)
    out.putPrefixedString(self.host_)
    for i in xrange(len(self.urls_)):
      out.putVarInt32(42)
      out.putVarInt32(self.urls_[i].ByteSize())
      self.urls_[i].OutputUnchecked(out)

  def TryMerge(self, d):
    while 1:
      tt = d.getVarInt32()
      if tt == 28: break
      if tt == 34:
        self.set_host(d.getPrefixedString())
        continue
      if tt == 42:
        length = d.getVarInt32()
        tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length)
        d.skip(length)
        self.add_urls().TryMerge(tmp)
        continue
      # tag 0 is special: it's used to indicate an error.
      # so if we see it we raise an exception.
      if (tt == 0): raise ProtocolBuffer.ProtocolBufferDecodeError
      d.skipData(tt)


  def __str__(self, prefix="", printElemNumber=0):
    res=""
    if self.has_host_: res+=prefix+("Host: %s\n" % self.DebugFormatString(self.host_))
    cnt=0
    for e in self.urls_:
      elm=""
      if printElemNumber: elm="(%d)" % cnt
      res+=prefix+("Urls%s <\n" % elm)
      res+=e.__str__(prefix + "  ", printElemNumber)
      res+=prefix+">\n"
      cnt+=1
    return res

class CrawlQueueResponse_FutureQueue(ProtocolBuffer.ProtocolMessage):
  def __init__(self, contents=None):
    self.urls_ = []
    if contents is not None: self.MergeFromString(contents)

  def urls_size(self): return len(self.urls_)
  def urls_list(self): return self.urls_

  def urls(self, i):
    return self.urls_[i]

  def mutable_urls(self, i):
    return self.urls_[i]

  def add_urls(self):
    x = UrlInfo()
    self.urls_.append(x)
    return x

  def clear_urls(self):
    self.urls_ = []

  def MergeFrom(self, x):
    assert x is not self
    for i in xrange(x.urls_size()): self.add_urls().CopyFrom(x.urls(i))

  def _CMergeFromString(self, s):
    _net_proto___parse__python.MergeFromString(self, 'CrawlQueueResponse', s)

  def _CEncode(self):
    return _net_proto___parse__python.Encode(self, 'CrawlQueueResponse')

  def _CToASCII(self, output_format):
    return _net_proto___parse__python.ToASCII(self, 'CrawlQueueResponse', output_format)


  def ParseASCII(self, s):
    _net_proto___parse__python.ParseASCII(self, 'CrawlQueueResponse', s)


  def ParseASCIIIgnoreUnknown(self, s):
    _net_proto___parse__python.ParseASCIIIgnoreUnknown(self, 'CrawlQueueResponse', s)


  def Equals(self, x):
    if x is self: return 1
    if len(self.urls_) != len(x.urls_): return 0
    for e1, e2 in zip(self.urls_, x.urls_):
      if e1 != e2: return 0
    return 1

  def __eq__(self, other):
    return (other is not None) and (other.__class__ == self.__class__) and self.Equals(other)

  def __ne__(self, other):
    return not (self == other)

  def IsInitialized(self, debug_strs=None):
    initialized = 1
    for i in xrange(len(self.urls_)):
      if (not self.urls_[i].IsInitialized(debug_strs)): initialized=0
    return initialized

  def ByteSize(self):
    n = 0
    n += 1 * len(self.urls_)
    for i in xrange(len(self.urls_)): n += self.lengthString(self.urls_[i].ByteSize())
    return n + 0

  def Clear(self):
    self.clear_urls()

  def OutputUnchecked(self, out):
    for i in xrange(len(self.urls_)):
      out.putVarInt32(58)
      out.putVarInt32(self.urls_[i].ByteSize())
      self.urls_[i].OutputUnchecked(out)

  def TryMerge(self, d):
    while 1:
      tt = d.getVarInt32()
      if tt == 52: break
      if tt == 58:
        length = d.getVarInt32()
        tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length)
        d.skip(length)
        self.add_urls().TryMerge(tmp)
        continue
      # tag 0 is special: it's used to indicate an error.
      # so if we see it we raise an exception.
      if (tt == 0): raise ProtocolBuffer.ProtocolBufferDecodeError
      d.skipData(tt)


  def __str__(self, prefix="", printElemNumber=0):
    res=""
    cnt=0
    for e in self.urls_:
      elm=""
      if printElemNumber: elm="(%d)" % cnt
      res+=prefix+("Urls%s <\n" % elm)
      res+=e.__str__(prefix + "  ", printElemNumber)
      res+=prefix+">\n"
      cnt+=1
    return res

class CrawlQueueResponse(ProtocolBuffer.ProtocolMessage):
  def __init__(self, contents=None):
    self.numurls_ = 0
    self.captiontime_ = 0
    self.hostqueue_ = []
    self.futurequeue_ = None
    self.has_numurls_ = 0
    self.has_captiontime_ = 0
    self.has_futurequeue_ = 0
    self.lazy_init_lock_ = thread.allocate_lock()
    if contents is not None: self.MergeFromString(contents)

  def numurls(self): return self.numurls_

  def set_numurls(self, x):
    self.has_numurls_ = 1
    self.numurls_ = x

  def clear_numurls(self):
    self.has_numurls_ = 0
    self.numurls_ = 0

  def has_numurls(self): return self.has_numurls_

  def captiontime(self): return self.captiontime_

  def set_captiontime(self, x):
    self.has_captiontime_ = 1
    self.captiontime_ = x

  def clear_captiontime(self):
    self.has_captiontime_ = 0
    self.captiontime_ = 0

  def has_captiontime(self): return self.has_captiontime_

  def hostqueue_size(self): return len(self.hostqueue_)
  def hostqueue_list(self): return self.hostqueue_

  def hostqueue(self, i):
    return self.hostqueue_[i]

  def mutable_hostqueue(self, i):
    return self.hostqueue_[i]

  def add_hostqueue(self):
    x = CrawlQueueResponse_HostQueue()
    self.hostqueue_.append(x)
    return x

  def clear_hostqueue(self):
    self.hostqueue_ = []
  def futurequeue(self):
    if self.futurequeue_ is None:
      self.lazy_init_lock_.acquire()
      try:
        if self.futurequeue_ is None: self.futurequeue_ = CrawlQueueResponse_FutureQueue()
      finally:
        self.lazy_init_lock_.release()
    return self.futurequeue_

  def mutable_futurequeue(self): self.has_futurequeue_ = 1; return self.futurequeue()

  def clear_futurequeue(self):
    #Warning: this method does not acquire the lock.
    self.has_futurequeue_ = 0;
    if self.futurequeue_ is not None: self.futurequeue_.Clear()

  def has_futurequeue(self): return self.has_futurequeue_


  def MergeFrom(self, x):
    assert x is not self
    if (x.has_numurls()): self.set_numurls(x.numurls())
    if (x.has_captiontime()): self.set_captiontime(x.captiontime())
    for i in xrange(x.hostqueue_size()): self.add_hostqueue().CopyFrom(x.hostqueue(i))
    if (x.has_futurequeue()): self.mutable_futurequeue().MergeFrom(x.futurequeue())

  def _CMergeFromString(self, s):
    _net_proto___parse__python.MergeFromString(self, 'CrawlQueueResponse', s)

  def _CEncode(self):
    return _net_proto___parse__python.Encode(self, 'CrawlQueueResponse')

  def _CToASCII(self, output_format):
    return _net_proto___parse__python.ToASCII(self, 'CrawlQueueResponse', output_format)


  def ParseASCII(self, s):
    _net_proto___parse__python.ParseASCII(self, 'CrawlQueueResponse', s)


  def ParseASCIIIgnoreUnknown(self, s):
    _net_proto___parse__python.ParseASCIIIgnoreUnknown(self, 'CrawlQueueResponse', s)


  def Equals(self, x):
    if x is self: return 1
    if self.has_numurls_ != x.has_numurls_: return 0
    if self.has_numurls_ and self.numurls_ != x.numurls_: return 0
    if self.has_captiontime_ != x.has_captiontime_: return 0
    if self.has_captiontime_ and self.captiontime_ != x.captiontime_: return 0
    if len(self.hostqueue_) != len(x.hostqueue_): return 0
    for e1, e2 in zip(self.hostqueue_, x.hostqueue_):
      if e1 != e2: return 0
    if self.has_futurequeue_ != x.has_futurequeue_: return 0
    if self.has_futurequeue_ and self.futurequeue_ != x.futurequeue_: return 0
    return 1

  def __eq__(self, other):
    return (other is not None) and (other.__class__ == self.__class__) and self.Equals(other)

  def __ne__(self, other):
    return not (self == other)

  def IsInitialized(self, debug_strs=None):
    initialized = 1
    if (not self.has_numurls_):
      initialized = 0
      if debug_strs is not None:
        debug_strs.append('Required field: numurls not set.')
    if (not self.has_captiontime_):
      initialized = 0
      if debug_strs is not None:
        debug_strs.append('Required field: captiontime not set.')
    for i in xrange(len(self.hostqueue_)):
      if (not self.hostqueue_[i].IsInitialized(debug_strs)): initialized=0
    if (self.has_futurequeue_ and not self.futurequeue_.IsInitialized(debug_strs)): initialized = 0
    return initialized

  def ByteSize(self):
    n = 0
    n += self.lengthVarInt64(self.numurls_)
    n += self.lengthVarInt64(self.captiontime_)
    n += 2 * len(self.hostqueue_)
    for i in xrange(len(self.hostqueue_)): n += self.hostqueue_[i].ByteSize()
    if (self.has_futurequeue_): n += 2 + self.futurequeue_.ByteSize()
    return n + 2

  def Clear(self):
    self.clear_numurls()
    self.clear_captiontime()
    self.clear_hostqueue()
    self.clear_futurequeue()

  def OutputUnchecked(self, out):
    out.putVarInt32(8)
    out.putVarInt32(self.numurls_)
    out.putVarInt32(16)
    out.putVarInt32(self.captiontime_)
    for i in xrange(len(self.hostqueue_)):
      out.putVarInt32(27)
      self.hostqueue_[i].OutputUnchecked(out)
      out.putVarInt32(28)
    if (self.has_futurequeue_):
      out.putVarInt32(51)
      self.futurequeue_.OutputUnchecked(out)
      out.putVarInt32(52)

  def TryMerge(self, d):
    while d.avail() > 0:
      tt = d.getVarInt32()
      if tt == 8:
        self.set_numurls(d.getVarInt32())
        continue
      if tt == 16:
        self.set_captiontime(d.getVarInt32())
        continue
      if tt == 27:
        self.add_hostqueue().TryMerge(d)
        continue
      if tt == 51:
        self.mutable_futurequeue().TryMerge(d)
        continue
      # tag 0 is special: it's used to indicate an error.
      # so if we see it we raise an exception.
      if (tt == 0): raise ProtocolBuffer.ProtocolBufferDecodeError
      d.skipData(tt)


  def __str__(self, prefix="", printElemNumber=0):
    res=""
    if self.has_numurls_: res+=prefix+("NumURLs: %s\n" % self.DebugFormatInt32(self.numurls_))
    if self.has_captiontime_: res+=prefix+("CaptionTime: %s\n" % self.DebugFormatInt32(self.captiontime_))
    cnt=0
    for e in self.hostqueue_:
      elm=""
      if printElemNumber: elm="(%d)" % cnt
      res+=prefix+("HostQueue%s {\n" % elm)
      res+=e.__str__(prefix + "  ", printElemNumber)
      res+=prefix+"}\n"
      cnt+=1
    if self.has_futurequeue_:
      res+=prefix+"FutureQueue {\n"
      res+=self.futurequeue_.__str__(prefix + "  ", printElemNumber)
      res+=prefix+"}\n"
    return res

  kNumURLs = 1
  kCaptionTime = 2
  kHostQueueGroup = 3
  kHostQueueHost = 4
  kHostQueueUrls = 5
  kFutureQueueGroup = 6
  kFutureQueueUrls = 7

  _TEXT = (
   "ErrorCode",  #   0
   "NumURLs",  #   1
   "CaptionTime",  #   2
   "HostQueue",  #   3
   "Host",  #   4
   "Urls",  #   5
   "FutureQueue",  #   6
   "Urls",  #   7
  )

  _TYPES = (
   ProtocolBuffer.Encoder.NUMERIC,  #   0
   ProtocolBuffer.Encoder.NUMERIC,  #   1

   ProtocolBuffer.Encoder.NUMERIC,  #   2

   ProtocolBuffer.Encoder.STARTGROUP,  #   3

   ProtocolBuffer.Encoder.STRING,  #   4

   ProtocolBuffer.Encoder.STRING,  #   5

   ProtocolBuffer.Encoder.STARTGROUP,  #   6

   ProtocolBuffer.Encoder.STRING,  #   7

  )

  # stylesheet for XML output
  _STYLE = \
   """"""
  _STYLE_CONTENT_TYPE = \
   """"""
  _SERIALIZED_DESCRIPTOR = array.array('B', [
    0x5a,
    0x3d,
    0x65,
    0x6e,
    0x74,
    0x65,
    0x72,
    0x70,
    0x72,
    0x69,
    0x73,
    0x65,
    0x2f,
    0x73,
    0x75,
    0x70,
    0x65,
    0x72,
    0x67,
    0x73,
    0x61,
    0x2f,
    0x70,
    0x6c,
    0x61,
    0x6e,
    0x6e,
    0x65,
    0x72,
    0x2f,
    0x6c,
    0x6f,
    0x6e,
    0x67,
    0x70,
    0x6c,
    0x61,
    0x6e,
    0x6e,
    0x65,
    0x72,
    0x2f,
    0x72,
    0x70,
    0x63,
    0x2f,
    0x63,
    0x72,
    0x61,
    0x77,
    0x6c,
    0x72,
    0x65,
    0x70,
    0x6f,
    0x72,
    0x74,
    0x2e,
    0x70,
    0x72,
    0x6f,
    0x74,
    0x6f,
    0x0a,
    0x12,
    0x43,
    0x72,
    0x61,
    0x77,
    0x6c,
    0x51,
    0x75,
    0x65,
    0x75,
    0x65,
    0x52,
    0x65,
    0x73,
    0x70,
    0x6f,
    0x6e,
    0x73,
    0x65,
    0x13,
    0x1a,
    0x07,
    0x4e,
    0x75,
    0x6d,
    0x55,
    0x52,
    0x4c,
    0x73,
    0x20,
    0x01,
    0x28,
    0x00,
    0x30,
    0x05,
    0x38,
    0x02,
    0x14,
    0x13,
    0x1a,
    0x0b,
    0x43,
    0x61,
    0x70,
    0x74,
    0x69,
    0x6f,
    0x6e,
    0x54,
    0x69,
    0x6d,
    0x65,
    0x20,
    0x02,
    0x28,
    0x00,
    0x30,
    0x05,
    0x38,
    0x02,
    0x14,
    0x13,
    0x1a,
    0x09,
    0x48,
    0x6f,
    0x73,
    0x74,
    0x51,
    0x75,
    0x65,
    0x75,
    0x65,
    0x20,
    0x03,
    0x28,
    0x03,
    0x30,
    0x0a,
    0x38,
    0x03,
    0x14,
    0x13,
    0x1a,
    0x0e,
    0x48,
    0x6f,
    0x73,
    0x74,
    0x51,
    0x75,
    0x65,
    0x75,
    0x65,
    0x2e,
    0x48,
    0x6f,
    0x73,
    0x74,
    0x20,
    0x04,
    0x28,
    0x02,
    0x30,
    0x09,
    0x38,
    0x02,
    0x60,
    0x02,
    0x14,
    0x13,
    0x1a,
    0x0e,
    0x48,
    0x6f,
    0x73,
    0x74,
    0x51,
    0x75,
    0x65,
    0x75,
    0x65,
    0x2e,
    0x55,
    0x72,
    0x6c,
    0x73,
    0x20,
    0x05,
    0x28,
    0x02,
    0x30,
    0x0b,
    0x38,
    0x03,
    0x4a,
    0x07,
    0x55,
    0x72,
    0x6c,
    0x49,
    0x6e,
    0x66,
    0x6f,
    0x60,
    0x02,
    0x14,
    0x13,
    0x1a,
    0x0b,
    0x46,
    0x75,
    0x74,
    0x75,
    0x72,
    0x65,
    0x51,
    0x75,
    0x65,
    0x75,
    0x65,
    0x20,
    0x06,
    0x28,
    0x03,
    0x30,
    0x0a,
    0x38,
    0x01,
    0x14,
    0x13,
    0x1a,
    0x10,
    0x46,
    0x75,
    0x74,
    0x75,
    0x72,
    0x65,
    0x51,
    0x75,
    0x65,
    0x75,
    0x65,
    0x2e,
    0x55,
    0x72,
    0x6c,
    0x73,
    0x20,
    0x07,
    0x28,
    0x02,
    0x30,
    0x0b,
    0x38,
    0x03,
    0x4a,
    0x07,
    0x55,
    0x72,
    0x6c,
    0x49,
    0x6e,
    0x66,
    0x6f,
    0x60,
    0x05,
    0x14,
    ])
  _net_proto___parse__python.RegisterType(_SERIALIZED_DESCRIPTOR.tostring())

__all__ = ['CrawlReportRequest','CrawlReportRequest_UrlInfoParams','CrawlReportRequest_CrawlQueueParams','UrlInfo','CrawlQueueResponse','CrawlQueueResponse_HostQueue','CrawlQueueResponse_FutureQueue']
